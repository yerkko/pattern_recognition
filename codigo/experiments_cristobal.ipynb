{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Extracción de features ------------------------------------------------\nExtrayendo features de training...\n"
    }
   ],
   "source": [
    "# Librerías externas\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from skimage.feature import hog\n",
    "\n",
    "\n",
    "def extract_color_features(colored_img):\n",
    "    hog_image = hog(colored_img, pixels_per_cell=(8, 8),\n",
    "                     cells_per_block=(4, 4), transform_sqrt=True, visualize=False, multichannel=True)\n",
    "    return hog_image.flatten()\n",
    "\n",
    "\n",
    "print(\"Extracción de features ------------------------------------------------\")\n",
    "\n",
    "print(\"Extrayendo features de training...\")\n",
    "\n",
    "# Los cropped son considerando la imagen con y de 0:128, y x de 32:-32.\n",
    "# Los no cropped son considerando la imagen con y de 0:128.\n",
    "X_train = []\n",
    "X_train_cropped = []\n",
    "X_val = []\n",
    "X_val_cropped = []\n",
    "X_test = []\n",
    "X_test_cropped = []\n",
    "d_train = []\n",
    "d_val = []\n",
    "d_test = []\n",
    "\n",
    "# Leemos las imagenes de training\n",
    "directory = \"FaceMask166\"\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.startswith(\".\"):\n",
    "        continue\n",
    "\n",
    "    # Obtenemos la clasificación\n",
    "    classification = int(filename[5:8])\n",
    "\n",
    "    # Obtenemos la imagen\n",
    "    filename_path = directory + '/' + filename\n",
    "    number = int(filename_path[-5])\n",
    "\n",
    "    # Obtenemos las imagen y la recortamos\n",
    "    img_colored = cv2.imread(filename_path)\n",
    "    img_colored_cropped = img_colored[0:128, 32:-32]\n",
    "\n",
    "    # Obtenemos la imagen flipped\n",
    "    img_colored_flipped = cv2.imread(filename_path)\n",
    "    img_colored_flipped = cv2.flip(img_colored_flipped, 1)\n",
    "\n",
    "    # Obtenemos la imagen flipped y la recortamos\n",
    "    img_colored_flipped_cropped = img_colored_flipped[0:128, 32:-32]\n",
    "    img_colored_flipped_cropped = cv2.flip(img_colored_flipped_cropped, 1)\n",
    "\n",
    "    # Obtenemos las features para no cropped\n",
    "    features = extract_color_features(img_colored)\n",
    "    features_flipped = extract_color_features(img_colored_flipped)\n",
    "\n",
    "    # Obtenemos las features para cropped\n",
    "    features_cropped = extract_color_features(img_colored_cropped)\n",
    "    features_flipped_cropped = extract_color_features(img_colored_flipped_cropped)\n",
    "\n",
    "    # Las guardamos\n",
    "    if number in {1, 2, 3}:\n",
    "        X_train.append(np.array(features))\n",
    "        X_train.append(np.array(features_flipped))\n",
    "        X_train_cropped.append(np.array(features_cropped))\n",
    "        X_train_cropped.append(np.array(features_flipped_cropped))\n",
    "\n",
    "        d_train.append(classification)\n",
    "        d_train.append(classification)\n",
    "    elif number == 4:\n",
    "        X_val.append(np.array(features))\n",
    "        d_val.append(classification)\n",
    "    elif number in {5, 6}:\n",
    "        X_test.append(np.array(features))\n",
    "        d_test.append(classification)\n",
    "\n",
    "# Convertimos los datos a arrays\n",
    "X_train = np.array([np.array(xi) for xi in X_train])\n",
    "X_test = np.array([np.array(xi) for xi in X_test])\n",
    "X_val = np.array([np.array(xi) for xi in X_val])\n",
    "X_train_cropped = np.array([np.array(xi) for xi in X_train])\n",
    "X_test_cropped = np.array([np.array(xi) for xi in X_test])\n",
    "X_val_cropped = np.array([np.array(xi) for xi in X_val])\n",
    "d_train = np.array(d_train).astype(int)\n",
    "d_test = np.array(d_test).astype(int)\n",
    "d_val = np.array(d_val).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d369855c8a97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# Librerías internas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Ignore warnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'model'"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import svm\n",
    "from warnings import simplefilter\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Librerías externas\n",
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore warnings\n",
    "from warnings import simplefilter\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "\n",
    "def get_train_test_val(X_train, X_test, X_val, d_train, d_test, d_val, l, augmented=True):\n",
    "    dic = {'A': 16, 'B': 40, 'C': 100, 'D': 166}\n",
    "    N = dic[l]\n",
    "    n = 3\n",
    "    if augmented:\n",
    "        n = 6\n",
    "    \n",
    "    # Por ejemplo, para 16 datos (N = 16, conjunto A), tendremos:\n",
    "    #   16 * 6 imágenes de training (6 por persona)\n",
    "    #   16 * 2 imagenes de training (2 por persona)\n",
    "    #   16 imagenes de validación (1 por persona)\n",
    "    return X_train[:n*N], X_test[:2*N], X_val[:N], d_train[:n*N], d_test[:2*N], d_val[:N]\n",
    "\n",
    "max_acc_test = {'A': 0, 'B': 0, 'C': 0, 'D': 0}\n",
    "max_acc_val = {'A': 0, 'B': 0, 'C': 0, 'D': 0}\n",
    "max_acc_val_test = {'A': 0, 'B': 0, 'C': 0, 'D': 0}\n",
    "for l in ['A', 'B', 'C', 'D']:  # , 'B', 'C', 'D'}:\n",
    "    print(\"Resultados para non-cropped\")\n",
    "\n",
    "    # Dividimos los sets de datos\n",
    "    train, test, val, d_tr, d_te, d_v = get_train_test_val(\n",
    "        X_train, X_test, X_val, d_train, d_test, d_val, l)\n",
    "\n",
    "    # Normalizamos\n",
    "    normalization = MinMaxScaler(feature_range=(0, 1))\n",
    "    train_norm = normalization.fit_transform(train)\n",
    "    test_norm = normalization.transform(test)\n",
    "    val_norm = normalization.transform(val)\n",
    "\n",
    "    # Generamos el modelo de clasificación\n",
    "    m = svm.LinearSVC()\n",
    "\n",
    "    # Lo actualizamos con training\n",
    "    m.fit(train_norm,  d_tr)\n",
    "\n",
    "    # Predecimos\n",
    "    val_pred = m.predict(val_norm)\n",
    "    test_pred = m.predict(test_norm)\n",
    "    print(\"VAL\", l, accuracy_score(d_v, val_pred))\n",
    "\n",
    "    # Guardamos imagen para set validación\n",
    "    # cm = confusion_matrix(d_v, val_pred)\n",
    "    # f = sns.heatmap(cm, cmap=\"Blues\")\n",
    "    # plt.savefig(f\"cm_val_{l}.png\")\n",
    "    # plt.clf()#plt.clf()\n",
    "    print(\"TEST\", l, accuracy_score(d_te, test_pred))\n",
    "    \n",
    "    # Guardamos imagen para set training\n",
    "    # cm = confusion_matrix(d_te, test_pred)\n",
    "    # f = sns.heatmap(cm, cmap=\"Blues\")\n",
    "    # plt.savefig(f\"cm_test_{l}.png\")\n",
    "    # plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594662100496",
   "display_name": "Python 3.8.2 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}