{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('features\\datasetD_hog-color-v2_flipped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lbp = pd.read_csv(\"features\\datasetD_lbp_flipped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lbp_no_lab = df_lbp.drop(['Unnamed: 0', 'image_number', 'label'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_lab = df.drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_lab = pd.concat([df_no_lab, df_lbp_no_lab], axis = 1, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      label  image_number  hog-color-v2_0  hog-color-v2_1  hog-color-v2_2  \\\n0         1             1        0.000000        0.000000        0.000000   \n1         1             1        0.001802        0.000000        0.002428   \n2         1             2        0.108572        0.072784        0.112895   \n3         1             2        0.025007        0.000000        0.028293   \n4         1             3        0.137719        0.086321        0.164701   \n...     ...           ...             ...             ...             ...   \n1489    166             3        0.092195        0.102944        0.014417   \n1490    166             3        0.005697        0.000725        0.000891   \n1491    166             4        0.053747        0.012987        0.002982   \n1492    166             5        0.061189        0.193637        0.168394   \n1493    166             6        0.041157        0.000000        0.014074   \n\n      hog-color-v2_3  hog-color-v2_4  hog-color-v2_5  hog-color-v2_6  \\\n0           0.000000        0.000000        0.000000        0.000000   \n1           0.000000        0.042526        0.000000        0.001274   \n2           0.157649        0.109572        0.019131        0.032165   \n3           0.086761        0.102675        0.054439        0.004570   \n4           0.135325        0.240212        0.109219        0.105737   \n...              ...             ...             ...             ...   \n1489        0.000000        0.009899        0.002420        0.010604   \n1490        0.002078        0.006716        0.003648        0.023067   \n1491        0.004077        0.007800        0.000698        0.001951   \n1492        0.005620        0.034578        0.003297        0.000000   \n1493        0.040568        0.094287        0.078958        0.168680   \n\n      hog-color-v2_7  ...  lbp-4-8_1878  lbp-4-8_1879  lbp-4-8_1880  \\\n0           0.000000  ...             3             0            14   \n1           0.001154  ...            22             0             4   \n2           0.015373  ...             8             4             3   \n3           0.017104  ...            14             5            12   \n4           0.167649  ...             7            20             6   \n...              ...  ...           ...           ...           ...   \n1489        0.021591  ...            11             0             5   \n1490        0.003392  ...             5             0             9   \n1491        0.013911  ...             1             0             0   \n1492        0.005468  ...             8             0            22   \n1493        0.072443  ...             9             4            18   \n\n      lbp-4-8_1881  lbp-4-8_1882  lbp-4-8_1883  lbp-4-8_1884  lbp-4-8_1885  \\\n0                1             5             0             5             4   \n1                0             6             0             6             1   \n2               11             8             4             5            14   \n3                9             8             1             4             4   \n4                6             7            12             5             5   \n...            ...           ...           ...           ...           ...   \n1489             0            58             3            23             1   \n1490             0            76             1             5             0   \n1491             1             0             0             0             0   \n1492             8            27             1            18             0   \n1493             4            33             9            12             4   \n\n      lbp-4-8_1886  lbp-4-8_1887  \n0              355            37  \n1              310            46  \n2               42            74  \n3               62            71  \n4               55            91  \n...            ...           ...  \n1489           254            46  \n1490           336            27  \n1491           888             0  \n1492           287            46  \n1493           190            62  \n\n[1494 rows x 56178 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>image_number</th>\n      <th>hog-color-v2_0</th>\n      <th>hog-color-v2_1</th>\n      <th>hog-color-v2_2</th>\n      <th>hog-color-v2_3</th>\n      <th>hog-color-v2_4</th>\n      <th>hog-color-v2_5</th>\n      <th>hog-color-v2_6</th>\n      <th>hog-color-v2_7</th>\n      <th>...</th>\n      <th>lbp-4-8_1878</th>\n      <th>lbp-4-8_1879</th>\n      <th>lbp-4-8_1880</th>\n      <th>lbp-4-8_1881</th>\n      <th>lbp-4-8_1882</th>\n      <th>lbp-4-8_1883</th>\n      <th>lbp-4-8_1884</th>\n      <th>lbp-4-8_1885</th>\n      <th>lbp-4-8_1886</th>\n      <th>lbp-4-8_1887</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>3</td>\n      <td>0</td>\n      <td>14</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>5</td>\n      <td>4</td>\n      <td>355</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0.001802</td>\n      <td>0.000000</td>\n      <td>0.002428</td>\n      <td>0.000000</td>\n      <td>0.042526</td>\n      <td>0.000000</td>\n      <td>0.001274</td>\n      <td>0.001154</td>\n      <td>...</td>\n      <td>22</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>6</td>\n      <td>1</td>\n      <td>310</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.108572</td>\n      <td>0.072784</td>\n      <td>0.112895</td>\n      <td>0.157649</td>\n      <td>0.109572</td>\n      <td>0.019131</td>\n      <td>0.032165</td>\n      <td>0.015373</td>\n      <td>...</td>\n      <td>8</td>\n      <td>4</td>\n      <td>3</td>\n      <td>11</td>\n      <td>8</td>\n      <td>4</td>\n      <td>5</td>\n      <td>14</td>\n      <td>42</td>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.025007</td>\n      <td>0.000000</td>\n      <td>0.028293</td>\n      <td>0.086761</td>\n      <td>0.102675</td>\n      <td>0.054439</td>\n      <td>0.004570</td>\n      <td>0.017104</td>\n      <td>...</td>\n      <td>14</td>\n      <td>5</td>\n      <td>12</td>\n      <td>9</td>\n      <td>8</td>\n      <td>1</td>\n      <td>4</td>\n      <td>4</td>\n      <td>62</td>\n      <td>71</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0.137719</td>\n      <td>0.086321</td>\n      <td>0.164701</td>\n      <td>0.135325</td>\n      <td>0.240212</td>\n      <td>0.109219</td>\n      <td>0.105737</td>\n      <td>0.167649</td>\n      <td>...</td>\n      <td>7</td>\n      <td>20</td>\n      <td>6</td>\n      <td>6</td>\n      <td>7</td>\n      <td>12</td>\n      <td>5</td>\n      <td>5</td>\n      <td>55</td>\n      <td>91</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1489</th>\n      <td>166</td>\n      <td>3</td>\n      <td>0.092195</td>\n      <td>0.102944</td>\n      <td>0.014417</td>\n      <td>0.000000</td>\n      <td>0.009899</td>\n      <td>0.002420</td>\n      <td>0.010604</td>\n      <td>0.021591</td>\n      <td>...</td>\n      <td>11</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>58</td>\n      <td>3</td>\n      <td>23</td>\n      <td>1</td>\n      <td>254</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>1490</th>\n      <td>166</td>\n      <td>3</td>\n      <td>0.005697</td>\n      <td>0.000725</td>\n      <td>0.000891</td>\n      <td>0.002078</td>\n      <td>0.006716</td>\n      <td>0.003648</td>\n      <td>0.023067</td>\n      <td>0.003392</td>\n      <td>...</td>\n      <td>5</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>76</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>336</td>\n      <td>27</td>\n    </tr>\n    <tr>\n      <th>1491</th>\n      <td>166</td>\n      <td>4</td>\n      <td>0.053747</td>\n      <td>0.012987</td>\n      <td>0.002982</td>\n      <td>0.004077</td>\n      <td>0.007800</td>\n      <td>0.000698</td>\n      <td>0.001951</td>\n      <td>0.013911</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>888</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1492</th>\n      <td>166</td>\n      <td>5</td>\n      <td>0.061189</td>\n      <td>0.193637</td>\n      <td>0.168394</td>\n      <td>0.005620</td>\n      <td>0.034578</td>\n      <td>0.003297</td>\n      <td>0.000000</td>\n      <td>0.005468</td>\n      <td>...</td>\n      <td>8</td>\n      <td>0</td>\n      <td>22</td>\n      <td>8</td>\n      <td>27</td>\n      <td>1</td>\n      <td>18</td>\n      <td>0</td>\n      <td>287</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>1493</th>\n      <td>166</td>\n      <td>6</td>\n      <td>0.041157</td>\n      <td>0.000000</td>\n      <td>0.014074</td>\n      <td>0.040568</td>\n      <td>0.094287</td>\n      <td>0.078958</td>\n      <td>0.168680</td>\n      <td>0.072443</td>\n      <td>...</td>\n      <td>9</td>\n      <td>4</td>\n      <td>18</td>\n      <td>4</td>\n      <td>33</td>\n      <td>9</td>\n      <td>12</td>\n      <td>4</td>\n      <td>190</td>\n      <td>62</td>\n    </tr>\n  </tbody>\n</table>\n<p>1494 rows × 56178 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "df_no_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils_experiments.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, test = split_train_val_test(df_no_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      label  image_number  hog-color-v2_0  hog-color-v2_1  hog-color-v2_2  \\\n0         1             1        0.000000        0.000000        0.000000   \n1         1             1        0.001802        0.000000        0.002428   \n2         1             2        0.108572        0.072784        0.112895   \n3         1             2        0.025007        0.000000        0.028293   \n4         1             3        0.137719        0.086321        0.164701   \n...     ...           ...             ...             ...             ...   \n1486    166             1        0.065949        0.007331        0.005414   \n1487    166             2        0.051225        0.018977        0.058499   \n1488    166             2        0.006702        0.002534        0.000000   \n1489    166             3        0.092195        0.102944        0.014417   \n1490    166             3        0.005697        0.000725        0.000891   \n\n      hog-color-v2_3  hog-color-v2_4  hog-color-v2_5  hog-color-v2_6  \\\n0           0.000000        0.000000        0.000000        0.000000   \n1           0.000000        0.042526        0.000000        0.001274   \n2           0.157649        0.109572        0.019131        0.032165   \n3           0.086761        0.102675        0.054439        0.004570   \n4           0.135325        0.240212        0.109219        0.105737   \n...              ...             ...             ...             ...   \n1486        0.009797        0.117318        0.100507        0.181685   \n1487        0.030624        0.258081        0.159878        0.030598   \n1488        0.000000        0.016576        0.000000        0.000000   \n1489        0.000000        0.009899        0.002420        0.010604   \n1490        0.002078        0.006716        0.003648        0.023067   \n\n      hog-color-v2_7  ...  lbp-4-8_1878  lbp-4-8_1879  lbp-4-8_1880  \\\n0           0.000000  ...             3             0            14   \n1           0.001154  ...            22             0             4   \n2           0.015373  ...             8             4             3   \n3           0.017104  ...            14             5            12   \n4           0.167649  ...             7            20             6   \n...              ...  ...           ...           ...           ...   \n1486        0.151801  ...            17             0             4   \n1487        0.025271  ...            19             6            15   \n1488        0.000827  ...             2             0             1   \n1489        0.021591  ...            11             0             5   \n1490        0.003392  ...             5             0             9   \n\n      lbp-4-8_1881  lbp-4-8_1882  lbp-4-8_1883  lbp-4-8_1884  lbp-4-8_1885  \\\n0                1             5             0             5             4   \n1                0             6             0             6             1   \n2               11             8             4             5            14   \n3                9             8             1             4             4   \n4                6             7            12             5             5   \n...            ...           ...           ...           ...           ...   \n1486             0            11             1            61             6   \n1487             7             9             4            13             5   \n1488            48             0             0             1            63   \n1489             0            58             3            23             1   \n1490             0            76             1             5             0   \n\n      lbp-4-8_1886  lbp-4-8_1887  \n0              355            37  \n1              310            46  \n2               42            74  \n3               62            71  \n4               55            91  \n...            ...           ...  \n1486           125            43  \n1487           105            75  \n1488            50            93  \n1489           254            46  \n1490           336            27  \n\n[996 rows x 56178 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>image_number</th>\n      <th>hog-color-v2_0</th>\n      <th>hog-color-v2_1</th>\n      <th>hog-color-v2_2</th>\n      <th>hog-color-v2_3</th>\n      <th>hog-color-v2_4</th>\n      <th>hog-color-v2_5</th>\n      <th>hog-color-v2_6</th>\n      <th>hog-color-v2_7</th>\n      <th>...</th>\n      <th>lbp-4-8_1878</th>\n      <th>lbp-4-8_1879</th>\n      <th>lbp-4-8_1880</th>\n      <th>lbp-4-8_1881</th>\n      <th>lbp-4-8_1882</th>\n      <th>lbp-4-8_1883</th>\n      <th>lbp-4-8_1884</th>\n      <th>lbp-4-8_1885</th>\n      <th>lbp-4-8_1886</th>\n      <th>lbp-4-8_1887</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>3</td>\n      <td>0</td>\n      <td>14</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>5</td>\n      <td>4</td>\n      <td>355</td>\n      <td>37</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0.001802</td>\n      <td>0.000000</td>\n      <td>0.002428</td>\n      <td>0.000000</td>\n      <td>0.042526</td>\n      <td>0.000000</td>\n      <td>0.001274</td>\n      <td>0.001154</td>\n      <td>...</td>\n      <td>22</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>6</td>\n      <td>0</td>\n      <td>6</td>\n      <td>1</td>\n      <td>310</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.108572</td>\n      <td>0.072784</td>\n      <td>0.112895</td>\n      <td>0.157649</td>\n      <td>0.109572</td>\n      <td>0.019131</td>\n      <td>0.032165</td>\n      <td>0.015373</td>\n      <td>...</td>\n      <td>8</td>\n      <td>4</td>\n      <td>3</td>\n      <td>11</td>\n      <td>8</td>\n      <td>4</td>\n      <td>5</td>\n      <td>14</td>\n      <td>42</td>\n      <td>74</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>2</td>\n      <td>0.025007</td>\n      <td>0.000000</td>\n      <td>0.028293</td>\n      <td>0.086761</td>\n      <td>0.102675</td>\n      <td>0.054439</td>\n      <td>0.004570</td>\n      <td>0.017104</td>\n      <td>...</td>\n      <td>14</td>\n      <td>5</td>\n      <td>12</td>\n      <td>9</td>\n      <td>8</td>\n      <td>1</td>\n      <td>4</td>\n      <td>4</td>\n      <td>62</td>\n      <td>71</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>3</td>\n      <td>0.137719</td>\n      <td>0.086321</td>\n      <td>0.164701</td>\n      <td>0.135325</td>\n      <td>0.240212</td>\n      <td>0.109219</td>\n      <td>0.105737</td>\n      <td>0.167649</td>\n      <td>...</td>\n      <td>7</td>\n      <td>20</td>\n      <td>6</td>\n      <td>6</td>\n      <td>7</td>\n      <td>12</td>\n      <td>5</td>\n      <td>5</td>\n      <td>55</td>\n      <td>91</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1486</th>\n      <td>166</td>\n      <td>1</td>\n      <td>0.065949</td>\n      <td>0.007331</td>\n      <td>0.005414</td>\n      <td>0.009797</td>\n      <td>0.117318</td>\n      <td>0.100507</td>\n      <td>0.181685</td>\n      <td>0.151801</td>\n      <td>...</td>\n      <td>17</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>11</td>\n      <td>1</td>\n      <td>61</td>\n      <td>6</td>\n      <td>125</td>\n      <td>43</td>\n    </tr>\n    <tr>\n      <th>1487</th>\n      <td>166</td>\n      <td>2</td>\n      <td>0.051225</td>\n      <td>0.018977</td>\n      <td>0.058499</td>\n      <td>0.030624</td>\n      <td>0.258081</td>\n      <td>0.159878</td>\n      <td>0.030598</td>\n      <td>0.025271</td>\n      <td>...</td>\n      <td>19</td>\n      <td>6</td>\n      <td>15</td>\n      <td>7</td>\n      <td>9</td>\n      <td>4</td>\n      <td>13</td>\n      <td>5</td>\n      <td>105</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>1488</th>\n      <td>166</td>\n      <td>2</td>\n      <td>0.006702</td>\n      <td>0.002534</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.016576</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000827</td>\n      <td>...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>48</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>63</td>\n      <td>50</td>\n      <td>93</td>\n    </tr>\n    <tr>\n      <th>1489</th>\n      <td>166</td>\n      <td>3</td>\n      <td>0.092195</td>\n      <td>0.102944</td>\n      <td>0.014417</td>\n      <td>0.000000</td>\n      <td>0.009899</td>\n      <td>0.002420</td>\n      <td>0.010604</td>\n      <td>0.021591</td>\n      <td>...</td>\n      <td>11</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>58</td>\n      <td>3</td>\n      <td>23</td>\n      <td>1</td>\n      <td>254</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>1490</th>\n      <td>166</td>\n      <td>3</td>\n      <td>0.005697</td>\n      <td>0.000725</td>\n      <td>0.000891</td>\n      <td>0.002078</td>\n      <td>0.006716</td>\n      <td>0.003648</td>\n      <td>0.023067</td>\n      <td>0.003392</td>\n      <td>...</td>\n      <td>5</td>\n      <td>0</td>\n      <td>9</td>\n      <td>0</td>\n      <td>76</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>336</td>\n      <td>27</td>\n    </tr>\n  </tbody>\n</table>\n<p>996 rows × 56178 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['label','image_number'], axis = 1).to_numpy()\n",
    "y_train = train['label'].to_numpy()\n",
    "X_test = test.drop(['label','image_number'], axis = 1).to_numpy()\n",
    "y_test = test['label'].to_numpy()\n",
    "X_val = val.drop(['label','image_number'], axis = 1).to_numpy()\n",
    "y_val = val['label'].to_numpy()\n",
    "model = SelectKBest(k = 3000)\n",
    "model.fit(X_train,y_train)\n",
    "X_train = model.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.4939759036144578"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=1000, n_jobs = -1, bootstrap= False)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(model.transform(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-17966df0bdb9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"done in %0.3fs\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Best estimator found by grid search:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
    "clf = GridSearchCV(\n",
    "    SVC(kernel='linear', class_weight='balanced'), param_grid\n",
    ")\n",
    "clf = clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.5210843373493976"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "clf.score(model.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.0"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "svm = SVC(kernel = 'linear')\n",
    "svm.fit(X_train, y_train)\n",
    "svm.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.4939759036144578"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "svm.score(model.transform(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features is 20387 and input n_features is 54288 ",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-f8734bbaa321>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    497\u001b[0m         \"\"\"\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    425\u001b[0m         \"\"\"\n\u001b[0;32m    426\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    394\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m             raise ValueError(\"Number of features of the model must \"\n\u001b[0m\u001b[0;32m    397\u001b[0m                              \u001b[1;34m\"match the input. Model n_features is %s and \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m                              \u001b[1;34m\"input n_features is %s \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features is 20387 and input n_features is 54288 "
     ]
    }
   ],
   "source": [
    "dt.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.0"
     },
     "metadata": {},
     "execution_count": 114
    }
   ],
   "source": [
    "dt.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [\n",
    "('rf', RandomForestClassifier(n_estimators=10, random_state=42)),\n",
    "('knn', KNeighborsClassifier(n_neighbors = 2))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(x_2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression(), n_jobs = -1, passthrough = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "StackingClassifier(estimators=[('rf',\n                                RandomForestClassifier(n_estimators=10,\n                                                       random_state=42)),\n                               ('knn', KNeighborsClassifier(n_neighbors=2))],\n                   final_estimator=LogisticRegression(), n_jobs=-1)"
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.13253012048192772"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "clf.score(k200.transform(X_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'X_200' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-5aa03c7b3506>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.33\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_200' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_200, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "SVC(kernel='linear')"
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier(hidden_layer_sizes=(200,200,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "MLPClassifier(hidden_layer_sizes=(200, 200, 200))"
     },
     "metadata": {},
     "execution_count": 125
    }
   ],
   "source": [
    "nn.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.7125506072874493"
     },
     "metadata": {},
     "execution_count": 127
    }
   ],
   "source": [
    "nn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bita0c4827aa8034300ac0548bce8047282",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}